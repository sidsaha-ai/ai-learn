{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torch import Tensor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHelpers:  # pylint: disable=too-few-public-methods\n",
    "    \"\"\"\n",
    "    Class the defines class methods to read the data files and return tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _categorical_cols() -> list:\n",
    "        return [\n",
    "            'MSSubClass',\n",
    "            'MSZoning',\n",
    "            'Street',\n",
    "            'Alley',\n",
    "            'LotShape',\n",
    "            'LandContour',\n",
    "            'Utilities',\n",
    "            'LotConfig',\n",
    "            'LandSlope',\n",
    "            'Neighborhood',\n",
    "            'Condition1',\n",
    "            'Condition2',\n",
    "            'BldgType',\n",
    "            'HouseStyle',\n",
    "            'OverallQual',  # test whether to consider this categorical or numerical data\n",
    "            'OverallCond',  # test whether to consider this categorical or numerical data\n",
    "            'RoofStyle',\n",
    "            'RoofMatl',\n",
    "            'Exterior1st',\n",
    "            'Exterior2nd',\n",
    "            'MasVnrType',\n",
    "            'ExterQual',\n",
    "            'ExterCond',\n",
    "            'Foundation',\n",
    "            'BsmtQual',\n",
    "            'BsmtCond',\n",
    "            'BsmtExposure',\n",
    "            'BsmtFinType1',\n",
    "            'BsmtFinType2',\n",
    "            'Heating',\n",
    "            'HeatingQC',\n",
    "            'CentralAir',\n",
    "            'Electrical',\n",
    "            'KitchenQual',\n",
    "            'Functional',\n",
    "            'FireplaceQu',\n",
    "            'GarageType',\n",
    "            'GarageFinish',\n",
    "            'GarageQual',\n",
    "            'GarageCond',\n",
    "            'PavedDrive',\n",
    "            'PoolQC',\n",
    "            'Fence',\n",
    "            'MiscFeature',\n",
    "            'SaleType',\n",
    "            'SaleCondition',\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _numerical_cols() -> list:\n",
    "        return [\n",
    "            'LotFrontage',\n",
    "            'LotArea',\n",
    "            'MasVnrArea',\n",
    "            'BsmtFinSF1',\n",
    "            'BsmtFinSF2',\n",
    "            'BsmtUnfSF',\n",
    "            'TotalBsmtSF',\n",
    "            '1stFlrSF',\n",
    "            '2ndFlrSF',\n",
    "            'LowQualFinSF',\n",
    "            'GrLivArea',\n",
    "            'BsmtFullBath',\n",
    "            'BsmtHalfBath',\n",
    "            'FullBath',\n",
    "            'HalfBath',\n",
    "            'BedroomAbvGr',\n",
    "            'KitchenAbvGr',\n",
    "            'TotRmsAbvGrd',\n",
    "            'Fireplaces',\n",
    "            'GarageCars',\n",
    "            'GarageArea',\n",
    "            'WoodDeckSF',\n",
    "            'OpenPorchSF',\n",
    "            'EnclosedPorch',\n",
    "            '3SsnPorch',\n",
    "            'ScreenPorch',\n",
    "            'PoolArea',\n",
    "            'MiscVal',\n",
    "\n",
    "            # derived fields\n",
    "            'Age',\n",
    "            'RemodelAge',\n",
    "            'GarageAge',\n",
    "            'MoSinceSold',\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def _age(*, df: pd.DataFrame, source_col: str, target_col: str) -> pd.DataFrame:\n",
    "        current_year: int = dt.datetime.now().year\n",
    "\n",
    "        # add age as target_col\n",
    "        df[target_col] = df[source_col].apply(\n",
    "            lambda x: current_year - x if pd.notnull(x) else np.nan\n",
    "        )\n",
    "        df = df.drop(columns=[source_col])  # remove source column\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _months_since_sold(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        mo_sold_col: str = 'MoSold'\n",
    "        yr_sold_col: str = 'YrSold'\n",
    "\n",
    "        def _calculate(row):\n",
    "            sold_month = row[mo_sold_col]\n",
    "            sold_year = row[yr_sold_col]\n",
    "\n",
    "            if pd.isnull(sold_month) or pd.isnull(sold_year):\n",
    "                return np.nan\n",
    "\n",
    "            sale_date = dt.datetime(\n",
    "                year=int(sold_year),\n",
    "                month=int(sold_month),\n",
    "                day=1,\n",
    "            )\n",
    "            num_days: int = (dt.datetime.now() - sale_date).days\n",
    "            num_months: int = num_days // 30\n",
    "            return num_months\n",
    "\n",
    "        df['MoSinceSold'] = df.apply(_calculate, axis=1)\n",
    "        df = df.drop(columns=[mo_sold_col, yr_sold_col])\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _modify_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # replace `YearBuilt` with the age of the house\n",
    "        df = DataHelpers._age(df=df, source_col='YearBuilt', target_col='Age')\n",
    "        # replace `YearRemodAdd` with the remodel age of the house\n",
    "        df = DataHelpers._age(df=df, source_col='YearRemodAdd', target_col='RemodelAge')\n",
    "        # replace `GarageYrBlt` with the age of the garage\n",
    "        df = DataHelpers._age(df=df, source_col='GarageYrBlt', target_col='GarageAge')\n",
    "        # replace `MoSold` and `YrSold` with the number of months since sold\n",
    "        df = DataHelpers._months_since_sold(df)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def make_data(cls, csv_filepath: str) -> tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        The main function of this class to read the data files and return tensors that can\n",
    "        be used by the neural network.\n",
    "        \"\"\"\n",
    "        df: pd.DataFrame = pd.read_csv(csv_filepath)\n",
    "        if df.empty:\n",
    "            return None\n",
    "\n",
    "        df = cls._modify_columns(df)\n",
    "\n",
    "        # drop the rows where `SalePrice` is null\n",
    "        df = df.dropna(subset=['SalePrice'])\n",
    "\n",
    "        # drop the ID column, it's not be used in training\n",
    "        df = df.drop(columns=['Id'])\n",
    "\n",
    "        # divide into input data and output data\n",
    "        input_df: pd.DataFrame = df.drop(columns=['SalePrice'])\n",
    "        output_df: pd.DataFrame = df[['SalePrice']]\n",
    "\n",
    "        # categorize columns into numerical and categorical\n",
    "        categorical_cols: list = cls._categorical_cols()\n",
    "        numerical_cols: list = cls._numerical_cols()\n",
    "\n",
    "        # impute numerical columns to remove None values\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        input_df[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "        # scaler numerical columns\n",
    "        scaler = StandardScaler()\n",
    "        numerical_data = pd.DataFrame(\n",
    "            scaler.fit_transform(input_df[numerical_cols]),\n",
    "        )\n",
    "        # one-hot encode categorical columns after imputing\n",
    "        pipeline = Pipeline(steps=[\n",
    "            # impute None columns with `missing` value\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            # then one-hot encode them\n",
    "            ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "        ])\n",
    "        categorical_data = pd.DataFrame(\n",
    "            pipeline.fit_transform(input_df[categorical_cols]),\n",
    "        )\n",
    "\n",
    "        input_df = pd.concat(\n",
    "            [numerical_data, categorical_data],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            torch.tensor(input_df.values, dtype=torch.float32),\n",
    "            torch.tensor(output_df.values, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filepath = 'data/train.csv'\n",
    "input_df, output_df = DataHelpers.make_data(csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1460, 1])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1460, 333])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Learn Env)",
   "language": "python",
   "name": "ai_learn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
